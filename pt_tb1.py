# -*- coding: utf-8 -*-
"""pytorch_tensorboard1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TrbfIA4NxQCxS73gg0answwDROuDaJN8
"""

import random
import torch
import numpy as np
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.datasets.mnist as mnist
from torch.utils.tensorboard import SummaryWriter
from torch.utils.data import random_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# 設定批次大小
batch_size = 2000

# 讀取資料
train_data = mnist.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())  #totensor本身就會做normalize
test_data = mnist.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())
train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)

# 設定測試及&驗證集大小
dataset_size = len(test_data)
val_size = dataset_size // 2
test_size = dataset_size - val_size

# 將測試資料拆分為驗證集與測試集
val_data, test_data_split = random_split(test_data, [val_size, test_size])

# 建立 DataLoader
val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_data_split, batch_size=batch_size, shuffle=False)
print(len(test_loader))

# 初始化tensorboard
writer = SummaryWriter()

# 建立模型
class model(nn.Module):
  def __init__(self):
    super(model, self).__init__()
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1) #16*26*26
    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)  #32*13*13
    self.pool1 = nn.MaxPool2d(kernel_size=2)  #32*6*6
    self.act1 = nn.ReLU()
    self.flatten = nn.Flatten()
    self.fc1 = nn.Linear(in_features=32*6*6, out_features=10)

  def forward(self, x):
    x = self.conv1(x)
    x = self.conv2(x)
    x = self.pool1(x)
    x = self.act1(x)
    x = self.flatten(x)
    x = self.fc1(x)
    return x

model1 = model()
print(model1)
total_params = sum(p.numel() for p in model1.parameters())
print(f"模型總參數數量: {total_params}")

trainable_params = sum(p.numel() for p in model1.parameters() if p.requires_grad)
print(f"可訓練參數數量: {trainable_params}")

# 訓練一個epoch
def train_one_epoch(epoch):
  train_loss_total = 0
  for batch_idx, (data, target) in enumerate(train_data_loader):
    optimizer.zero_grad()
    output = model1(data)
    _, preds = torch.max(output, 1)
    train_loss = loss_fn(output, target)
    train_loss_total += train_loss
    train_loss.backward()
    optimizer.step()

  train_loss_avg = train_loss_total / len(train_data_loader)
  acc = accuracy_score(target, preds)
  print(f'train_acc:{acc}')
  writer.add_scalar('Acc/train', acc, epoch)
  writer.add_scalar('Loss/train', train_loss_avg, epoch)
  return train_loss_avg

# 驗證
def val_one_epoch(epoch):
  val_loss_total = 0
  for batch_idx, (data, target) in enumerate(val_loader):
    val_output = model1(data)
    _, preds = torch.max(val_output, 1)
    val_loss = loss_fn(val_output, target)
    val_loss_total += val_loss

  val_loss_avg = val_loss_total / len(val_loader)
  acc = accuracy_score(target, preds)
  print(f'val_acc:{acc}')
  writer.add_scalar('Acc/val', acc, epoch)
  writer.add_scalar('Loss/val', val_loss_avg, epoch)
  return val_loss_avg

# 設定超參數
epochs = 20
lr = 0.001
loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model1.parameters(), lr=lr)
dummy_input = torch.randn(1, 1, 28, 28)
writer.add_graph(model1, dummy_input)

# 訓練模型
for epoch in range(epochs):
  print(f'epoch:{epoch+1}')

  # 訓練
  model1.train()
  train_loss_avg = train_one_epoch(epoch)

  # 驗證
  model1.eval()
  with torch.no_grad():
    val_loss_avg = val_one_epoch(epoch)

  print(f'train_loss:{train_loss_avg}, val_loss:{val_loss_avg}')

# 儲存模型
torch.save(model1, './model.pt')

model1 = torch.load("./model.pt", map_location=torch.device('cpu'), weights_only=False)
model1.eval()

with torch.no_grad():
  for batch, (images, labels) in enumerate(test_loader):
    outputs = model1(images)
    _, preds = torch.max(outputs, 1)
    print("預測結果：", preds[:20])
    print("實際結果：", labels[:20])

# 產生混淆矩陣
cm = confusion_matrix(labels, preds)
print(cm)

# 繪製混淆矩陣
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()

# 在圖上標示數字
classes = np.unique(labels)
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes)
plt.yticks(tick_marks, classes)

thresh = cm.max() / 2
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, str(cm[i][j]),
                 ha="center", va="center",
                 color="white" if cm[i, j] > thresh else "black")

plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir=runs

